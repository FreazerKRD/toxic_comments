# toxic_comments
Detecting toxic comments via BERT model  
В ходе работы были загружены и подготовлены данные, после чего на их основании построены эмбеддинги предобученной моделью Toxic_BERT.  
После чего были обучены четыре модели для предсказания токсичности комментариев.

**Используемые библиотеки: Pandas, Numpy, Torch, Transformers, NTLK, Sklearn, Catboost, XGBoost, LightGBM.**

В ходе работы подготовил данные, после чего на их основании построил эмбеддинги предобученной моделью Toxic_BERT. После чего были обучены четыре модели для предсказания токсичности комментариев, показавшие очень близкие результаты как по метрике F1, так и по времени обучения и предсказания. 

Из моделей для финального тестирования была выбрана модель Catboost, имеющая наивысшую метрику F1 и хорошее время обучения. Тестирование на тестовой выборке показало стабильность модели, итоговая метрика F1 = 0.937.
